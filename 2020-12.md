# Work Log of December

---

## Week 1

---

### 12-01

* 计划
  * [ ] 熟悉书籍tag产出项目
  * [ ] 写wiki总结之前的书籍相似度项目 及 k12 审核项目
* 完成
  * 熟悉书籍tag产出项目 (进度20%)
    * 熟悉项目结构，原始数据，项目运行方式
  * 总结书籍相似度项目
* 收获
  * 无

---

### 12-02

* 计划
  * [ ] 总结审核项目
  * [ ] 熟悉书籍tag产出项目
* 完成
  * 熟悉书籍tag产出项目 （进度30%）
    * 熟悉原始数据
    * 熟悉关键脚本
      * `./routine.run.sh`
      * `./apps/preprocess/handlers/book_handler.py`
      * `./core/basic/model/tag_model.py`
* 收获
  
  * grep 检索
  
    ```bash
    # OR 检索
    grep -E '马保国|耗子尾汁|不讲武德|马老师|大意了|没有闪|69岁的老同志' k12_cs_fn_samples.
    # AND 检索
    cat k12_cs_fn_samples | grep 不讲武德 | grep 耗子尾汁
    ```

---

### 12-03

* 计划
  * [ ] 熟悉书籍tag产出项目
* 完成
  * 熟悉书籍tag产出项目 （进度40%）
    * 熟悉关键脚本
      * `./apps/feature/handler/book_chapter_handler.py`
      * `./apps/feature/handler/book_handler.py`
      * `./apps/feature/model/book_chapter_model.py`
      * `./core/basic/model/book_model.py`
* 收获
  * 无

---

### 12-04

* 计划
  * [ ] 熟悉书籍tag产出项目
* 完成
  * 上午开会，网易的审核系统销售会议
  * 熟悉关键脚本
    * `./core/basic/model/statistic_model.py`
    * `./apps/eigenfunc/model/book_model.py`
    * `./apps/eigenfunc/handler/merge_handler.py`
  * 报销申报，发票提交
* 收获
  * 无

---

### summary

---

## Week 2

---

### 12-07

* 计划
  * [x] 继续整理书籍tag产出项目
  * [ ] 提交书籍tag产出项目的更新到gitlab，摘取部分原始数据，尝试在自己的目录下跑通项目
  * [ ] 熟悉tags相关词项目
  * [ ] 为k12审核增加敏感词识别
* 完成
  * 继续梳理书籍tag产出项目 (90%)
    * filter_handler.py
  * 参加分享会
* 收获
  * DateFrame 重要函数
    * df.apply()
    * df.groupby()
    * df.sort_values()

---

### 12-08

* 计划
  * [x] 继续梳理tag产出项目
    * [ ] 拷贝项目代码及部分数据文件到自己的目录下，尝试跑通项目
    * [ ] 尝试拉取评论来更新书籍的comment特征
  * [ ] 梳理tags相关词项目
  * [ ] 为k12审核增加敏感词识别，增加标点符号处理
  * [ ] 制作ppt，准备对审核人员的培训
* 完成
  * 继续梳理tag产出项目（进度100%，完成全部代码的整理和注释）
* 收获
  * `collection`模块
    * `defaultdict(default_factory)`：当字典里的key不存在但被查找时，返回的不是`keyError`而是一个默认值。参数`factory_function`可以是`list`、`set`、`str`等等，作用是当`key`不存在时，返回的是`factory_function`的默认值，比如`list`对应[ ]，`str`对应的是空字符串，`set`对应set( )，`int`对应0

---

### 12-09

* 计划

  * [ ] 书籍tag产出项目
    * [ ] 拷贝项目代码及部分数据文件到自己的目录下，尝试跑通项目
    * [ ] 拉取评论来更新书籍的comment特征
  * [ ] 梳理tags相关词项目
  * [ ] 为k12审核增加敏感词识别，增加标点符号处理
  * [ ] 制作ppt，准备对审核人员的培训

* 完成

  * 跟审核部门开会讨论分享会事宜，跟审核、中台沟通风险识别的使用情况
  * 梳理ugc书评产出tag标签的过程
    * ugc_handler.py
    * comment_handler.py
  * 查找comment的数据源
  * 复制项目代码到自己的路径下，并复制必要的数据，尝试跑通项目
  * k12审核标点的问题原因在于个别审核人员，不用做处理

* 收获

  * 查看hadoop空间占用

    ```bash
    [SanJunipero@BJ-SJ-HADOOP-DEV-41 rd]$ df -h
    Filesystem                Size  Used Avail Use% Mounted on
    /dev/mapper/vg01-lv_root   50G   32G   16G  68% /
    tmpfs                     127G   45M  127G   1% /dev/shm
    /dev/sdm2                 194M   34M  151M  19% /boot
    /dev/sdm1                 128M   24M  104M  19% /boot/efi
    /dev/mapper/vg01-lv_data  162G   26G  129G  17% /data
    /dev/sda1                 1.8T  946G  795G  55% /hadoop/01
    /dev/sda2                 1.8T  589G  1.2T  34% /hadoop/02
    /dev/sdb1                 1.8T  1.2T  555G  69% /hadoop/03
    /dev/sdb2                 1.8T  895G  847G  52% /hadoop/04
    /dev/sdc1                 1.8T  1.1T  687G  61% /hadoop/05
    cm_processes              127G   55M  127G   1% /data/server/cm-5.11.0/run/cloudera-scm-agent/process
    ```

    

---

### 12-10

* 计划
  * [x] 在自己的目录下跑通项目
  * [ ] 获取新的书籍comment数据，统计命中的tags
  * [x] 准备机器审核科普内容，及制作ppt
* 完成
  * 在自己的目录下跑通项目
  * 书籍的comment数据在日志里，没有现成的，需要从日志中产出
  * 准备机器审核科普内容（30%）
    * 完成大纲
* 收获
  * 无

---

### 12-11

* 计划
  * [ ] 为k12 增加敏感词检测（马保国，耽美相关）
  * [x] 从过往日志中产出书籍评论数据
  * [ ] 使用新的评论特征产出新的书籍tags，与原有项目进行对比
  * [x] 发票报销：填写电子发票登记单
  
* 完成
  
  * 周会
  * 开发脚本，从过往日志中产出书籍评论数据（2018-12-09 至 2020-12-09）
  * 填写电子发票登记单
  
* 收获  

  * 查看计算机资源占用

    * ```bash
      free -g
      ```

---

### Summary

* 本周完成
  * 梳理书籍tag产出流程，具体计算方法，comment特征相关tag的产出过程
  * 根据例行任务的流程，逐步跑通项目
  * 准备分享会事宜
* 下周工作
  * [ ] 为k12 增加敏感词检测（马保国，耽美相关）
  * [ ] 例行从日志中产出书籍评论数据

---

## Week 3

---

### 12-14

* 计划
  * [ ] 增加例行任务，每日从日志中产出书籍评论数据
  * [x] 完成分享会ppt
  * [ ] 由新的书评数据，产出该特征的tag
  * [ ] 产出新的书籍tag，并与已有的数据进行对比
  * [x] 为k12增加敏感词检测（马保国，耽美相关）
* 完成
  * 为k12增加敏感词检测
  * 完成分享会ppt
  * 对评论数据进行处理，合并新旧评论数据
  * 开会讨论数据tag标签的修改方案
* 收获
  * 无

---

### 12-15

* 计划
  * [x] 分享会
  * [x] 由新的书评数据，产出该特征的tag
  * [ ] 产出新的书籍tag，并与已有的数据进行对比
* 完成
  * 分享会
  * 由新的书评数据，产出该特征的tag
  * 开会讨论书籍tag标签的修改方案，确定细节
  * 根据需求按照一二级分类统计书籍标签
* 收获
  * 无

---

### 12-16

* 计划
  * [x] 产出新的书籍tag，并与已有数据进行对比
  * [ ] 统计不同特征产生的标签的比例
* 完成
  * 产出新的书籍tag，并与已有数据进行对比
* 收获
  * 无

---

### 12-17

* 计划
  * [ ] 统计不同特征产生的标签的比例
* 完成
  * 开会讨论书籍标签更改项目
  * 根据运营给予的标签映射关系，产出新的书籍标签数据（男频、女频）
* 收获
  * 无

---

### 12-18

* 计划
  * [x] 周会，周报
  * [ ] 完成绩效自评
  * [x] 为审核部门导出正负样本各1万条
  * [ ] 与数据平台部门沟通新的协议
  
* 完成

  * 周会，周报

  * 为审核部门导出正负样本各1万条

  * 绩效自评：

    * 做的好的

      * 找到了接手项目前统计数据中ugc审核灌水召回率骤降的原因，9月16日 审核中台将灌水贴的识别依据，由使用网易结果全部切换为使用算法识别的结果后，数据恢复正常。

      * 升级，维护机审系统的统计项目，可视化审核统计结果，例行产出各类样本。

      * 开发免审模型（风险识别模型）：
        * 完成免审模型的开发，并将之服务化，于10月14日上线。并将相关统计结果加入例行邮件。统计结果显示， 在允许极少量遗漏（占比违规总量3%以内）的情况下，UGC审核可以从全审做到书城的60%免审，K12可以从12%免审做到80%免审。
        * 于12月16审核中台完成了相应的排序和筛选功能支持，业务方开始正式使用。 

      * K12机器审核的优化：11月15日前后审核结果统计数据显示在违规识别精确率从38%提升到50%左右的情况下，召回率由55%提高到89%。

        

    * 有待提高的 ：

      * 代码质量有待提高，包括规范变量、方法名， 规范注释，规范代码结构等。需要注意养成好的习惯，提高代码的可维护性。
      * 对Linux系统的熟悉程度有待提高，当下对一些常用到的命令和工具还不够熟练，一定程度上限制了自己的工作效率。
      * 风险意识有待提高。由于服务器是整个团队在使用，一个人的操作如果不规范，或是没有监控自己程序的运行状况，很有可能影响其他同事正在进行的任务。需要提高这方面的意识，养成良好习惯。

* 收获

  * 无

---

### summary

* 本周完成
  * 按照一、二级分类对书籍标签进行统计
  * 根据运营给予的标签映射、关键词映射，产出规定格式的新的书籍标签数据
  * 整合新、旧书籍评论数据，并根据评论产出书籍tag，与之前的结果进行对比
  * 为k12增加敏感词检测
  * 为审核部门导出样本
  * 培训审核部门，介绍机审系统
* 下周计划：
  * 与数据平台部门沟通新的协议
  * 统计不同特征产生的标签的比例

---

## Week 4

---

### 12-21

* 计划
  * [x] 根据运营部门需求，采用三种映射方式，产出新的书籍标签
  * [ ] 按照数据平台部门的需求，产出三份书籍标签相关数据
  * [ ] 查找17日机审系统统计数据异常的原因
  * [ ] 统计不同特征产生的标签的比例
* 完成
  * 根据运营部门需求，采用三种映射方式，产出新的书籍标签数据，共4分数据
* 收获
  * 无

---

### 12-22

* 计划
  * [x] 按照数据平台部门的需求，产出三份书籍标签相关数据
  * [ ] 查找17日机审系统统计数据异常的原因
  * [ ] 统计不同特征产生的标签的比例
* 完成
  * 按照数据平台部门的需求，产出三份书籍标签相关数据
* 收获
  * 无

---

### 12-23

* 计划
  * [ ] 查找17日机审系统统计数据异常的原因
  * [ ] 统计算法标签产出过程中，不同特征产生的标签的比例
  * [ ] 将UGC审核的高风险也算作违规，加入统计结果，分析下掉网易机审是否合理
  * [x] 完成360绩效评价
* 完成
  * 统计新标签对书籍的覆盖情况
  * 修改代码bug
  * 与运营沟通调整映射关系，使得所有书籍在新的标签体系下都至少能有一个标签
  * 完成360绩效评价
* 收获
  * 无

---

### 12-24

* 计划
  * [x] 根据运营需求，导出出版书籍的分类信息
  * [ ] 查找17日机审系统统计数据异常的原因
  * [ ] 统计算法标签产出过程中，不同特征产生的标签的比例
  * [ ] 将UGC审核的高风险也算作违规，加入统计结果，分析下掉网易机审是否合理
  * [ ] 将网易正确识别的违规文本保存为文件并作为附件随每日例行统计邮件发送
* 完成
  * 完善代码注释
  * 根据运营需求，导出出版书籍的分类信息等可用于映射新标签的信息
  * 根据平台需求，产出一版新的书籍标签信息
  * 开会讨论2021年Q1的项目计划
* 收获
  * 无

---

### 12-25

* 计划

  * [x] 查找17日机审系统统计数据异常的原因
  * [ ] 统计算法标签产出过程中，不同特征产生的标签的比例
  * [ ] 将UGC审核的高风险也算作违规，加入统计结果，分析下掉网易机审是否合理
  * [ ] 将网易正确识别的违规文本保存为文件并作为附件随每日例行统计邮件发送
  * [ ] 外部网站书籍标签爬取，查看相关项目

* 完成

  * 查找17日机审系统统计数据异常的原因
    * 17日和23日统计失败的原因，是k12审核数据中含有utf-8方式无法读取的数据，手动调整数据后补上了这两天的统计结果
  * 根据运营设计的规则，为出版书籍映射新的速看标签，产出交付数据

* 收获

  * 查看一个进程启动的路径

  * ```bash
    # pwdx PID
    pwdx 419384
    ```

---

### summary

* 本周完成
  * 从原始数据中产出多分46项目书籍的特征，配合运营部门的标签体系设计工作。
  * 根据运营部门设定的规则，为男频，女频，出版书籍映射新的速看标签。
  * 与平台订立新的协议，产出交付数据.
  * 统计速看标签对书籍的覆盖情况，配合运营解决覆盖不全的问题。
  * 维护机审统计服务, 查找17日，23日统计服务失败的原因。原因：k12审核日志中含有utf-8方式无法读取的数据
* 下周计划
  * [ ] 统计算法标签产出过程中，不同特征产生的标签的比例
  * [ ] 将UGC审核的高风险也算作违规，加入统计结果，分析下掉网易机审是否合理
  * [ ] 将网易正确识别的违规文本保存为文件并作为附件随每日例行统计邮件发送
  * [ ] 外部网站书籍标签爬取，查看相关项目

---

## Week 5

---

### 12-28

* 计划
  * [ ] 统计算法标签产出过程中，不同特征产生的标签的比例
  * [ ] 将UGC审核的高风险也算作违规，加入统计结果，分析下掉网易机审是否合理
  * [x] 将网易正确识别的违规文本保存为文件并作为附件随每日例行统计邮件发送
  * [ ] 外部网站书籍标签爬取，查看相关项目
* 完成
  * 修复，重跑审核系统每日例行统计任务
  * 将网易正确识别的违规文本保存为文件并作为附件随每日例行统计邮件发送
  * 为运营部门导出网文中一级分类既是男频又是女频的书
  * 统计不统阈值下，bert模型对 "算法机审漏召回的违规样本" 的识别情况，计算召回率，精确率等指标。选取0.9为阈值，高于0.9的全部判为违规，违规原因标识为 "bert"
* 收获
  * 无

---

### 12-29

* 计划

  * [x] 修改UGC审核代码，将部分bert判别为高风险的文本，判别为违规（选取0.9为阈值，高于0.9的全部判为违规，违规原因标识为 "bert"）
  * [x] 统计算法标签产出过程中，不同特征产生的标签的比例
  * [ ] 外部网站书籍标签爬取，查看相关项目
  * [ ] 将每周一例行产出的阅文书高风险书评中已经被删除的书评剔除

* 完成

  * 修改UGC审核代码，将部分bert判别为高风险的文本，判别为违规（选取0.9为阈值，高于0.9的全部判为违规，违规原因标识为 "bert"， code为22）

  * 统计算法标签产出过程中，不同特征产生的标签的比例

* 收获

  * 无

---

### 12-30

* 计划

  * [x] 补全数据，重跑标签来源统计
  * [x] 补发统计邮件
  * [ ] 外部网站书籍标签爬取，查看相关项目
  * [ ] 将每周一例行产出的阅文书高风险书评中已经被删除的书评剔除

* 完成

  * 修改标签来源统计脚本，重跑统计任务

    * 书籍总数：131236

      | 特征名      | 贡献标签总数 | 平均贡献标签数 | 贡献总频数 | 平均贡献频数 | 贡献标签覆盖书籍量 | 覆盖书籍比例 |
      | ----------- | ------------ | -------------- | ---------- | ------------ | ------------------ | ------------ |
      | chapter_res | 3155471      | 24.0442        | 8553041    | 65.173       | 86691              | 66.06%       |
      | name_res    | 237329       | 1.8084         | 239463     | 1.8247       | 84214              | 64.17%       |
      | brief_res   | 780095       | 5.9442         | 938932     | 7.1545       | 122580             | 93.40%       |
      | tag_res     | 1040282      | 7.9268         | 1049700    | 7.9986       | 130583             | 99.50%       |
      | keyword_res | 1052804      | 8.0222         | 1062756    | 8.0981       | 130601             | 99.52%       |
      | c2_res      | 210174       | 1.6015         | 210175     | 1.6015       | 109314             | 83.30%       |
      | c3_res      | 13859        | 0.1056         | 13859      | 0.1056       | 8020               | 6.11%        |
      | comment_res | 779080       | 5.9365         | 3556206    | 27.0978      | 27213              | 20.74%       |

    * 得到的结果依旧不能直观说明各个特征对于结果的贡献度

  * 补发例行统计邮件，发现例行任务失败的原因依然是日志错误，找到日志错误位置

* 收获

  * 无

---

### 12-31

* 计划

  * [x] 修改代码，重跑统计任务
  * [ ] 外部网站书籍标签爬取，查看学习相关项目
  * [ ] 将每周一例行产出的阅文书高风险书评中已经被删除的书评剔除

* 完成

  * 修改代码，重跑统计任务

    * 取样数1000本

    * | 特征范围             | 有标签的书籍 | 占比  | 标签总量 | 平均标签量 | 变化率 |
      | -------------------- | ------------ | ----- | -------- | ---------- | ------ |
      | 使用全部特征         | 983          | 98.3% | 9245     | 9.245      | /      |
      | 不使用书籍前三章特征 | 960          | 96%   | 5084     | 5.084      | - 45%  |

    * 目前的书籍列表中共有书籍 131236，其中有前三章数据的有 88052 本，约占67.1%

  * 下载安装学习Scrapy

  * 参加周会，完成周报

* 收获

  * 无

---

### summary

* 本周完成
  * “速看”项目：
    * 为运营部门导出所有网文中一级分类既是男频又是女频的书籍信息
  * 机器审核：
    * 修改UGC审核代码，将部分bert判别为高风险的文本，判别为违规（选取0.9为阈值，高于0.9的全部判为违规，status = 1， info = bert， code = 22
    * 统计不同阈值下，bert模型对 "算法机审漏召回的违规样本" 的识别情况，计算召回率，精确率等指标。最终选取0.9为阈值，高于0.9的全部判为违规，违规原因标识为 "bert"
    * 将网易正确识别的违规文本保存为文件并作为附件随每日例行统计邮件发送
    * 修复，重跑审核系统每日例行统计任务，发现问题依旧是k12的审核日志存在错误，无法读取，手动将错误行删除后（修复办法：合并日志，逐行读取文件并打印序号，得到中断位置，打开文件到中断位置，搜索k12找到错误行）
  * 书籍tag产出项目
    * 统计算法标签产出过程中，merge前不同特征产生的标签的比例
      * 得到的结果依旧不能直观说明各个特征对于结果的贡献度
    * 修改标签来源统计脚本，重跑统计任务，统计书籍前三章对应最终标签的影响
* 下周计划
  * [ ] 外部网站书籍标签爬取，查看学习相关项目
  * [ ] 将每周一例行产出的阅文书高风险书评中已经被删除的书评剔除

---

## Summary of December

---

