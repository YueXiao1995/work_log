# Work Log of March

---

## Week 1

---

### 03-01

* 计划
  * [ ] 产出一版新的网文标签
  * [x] 开发机审安全策略（政治敏感）
  * [ ] 学习awk命令语法
* 完成
  * 开发机审安全策略
    * 拼音检测
    * 词语组合检测
    * 派生敏感词检测
* 收获
  * 无

---

### 03-02

* 计划
  * [ ] 在机审服务中加入新的安全策略，并在测试后上线
  * [ ] 书籍tag项目使用头10章数据
  * [ ] 重新完整的跑一遍重构后的书籍标签拓展项目
* 完成
  * 观察k12审核的高中低风险及漏审文本，总结敏感词（敏感文本，敏感读音，敏感组合，敏感词派生变形）
  * 修改新增安全策略代码，由python3 改为 python2 （因为机审项目使用python2）
    * 因为无法再服务器上安装pypinyin包，所以没有进行测试上线
* 收获
  * [python2 和 python3 中的编码问题](https://www.zhihu.com/question/24891833)
  * [python 编码问题](https://www.cnblogs.com/chaojiyingxiong/p/9822444.html)

---

### 03-03

* 计划

  * [ ] 测试上线新的安全策略
  * [ ] 使用书籍头10章的数据
  * [ ] 重新完整的跑一遍重构后的书籍标签拓展项目

* 完成

  * 在pip链接外网的情况下，手动安装pypinyin到机审服务运行环境。
    * 下载包，rz到服务器，解压，python setup.py install安装，测试是否可以正常import，如果有依赖的包需要安装，则重复上述步骤
    * 修改代码，将新的安全策略加入机审服务中，在测试端口进行测试。
  * 在书籍tag产出项目中添加一本人工干预的书。
  * 查看审核中昵称检测的相关逻辑，导出相关数据库。

* 收获

  * 安装包到指定环境

    ```bash
    # 以项目运行环境为 /home/web/work/python2/bin/python 为例，安装pypinyin
    # 若pip可用
    /home/web/work/python2/bin/pip install pypinyin 
    
    # 若pip或conda不可用
    从github上下载pypinyin压缩包到工作机
    rz 
    unzip python-pinyin-master.zip
    cd python-pypinyin-master
    /home/web/work/python2/bin/python setup.py install
    ```

---

### 03-04

* 计划
  * [x] 测试上线新的安全策略
  * [ ] 使用书籍头10章的数据
  * [ ] 重新完整的跑一遍重构后的书籍标签拓展项目，并用全部的豆瓣数据训练一个模型
  * [x] 发票报销申请
* 完成
  * 测试上线新的安全策略，包括涉政敏感词检测，和k12敏感词检测，预计3月7日的统计邮件中可以看到明显变化。
  * 发票报销申请
* 收获
  * 无

---

### 03-05

* 计划
  * [ ] 使用书籍头10章的数据
  * [ ] 重新完整的跑一遍重构后的书籍标签拓展项目，融合人工标签
* 完成
  * 重跑出版书籍的标签拓展项目，优化模型及融合策略
    * 产出没有tfidf数据的书籍（将来单独进行预测、过滤及融合）
    * 重新训练出版书embedding模型，出版书标签预测模型（3个）
* 收获
  * 无

---

### Summary

* 本周完成
  * 开发涉政机审安全策略，识别谐音，组合，首字母组合等涉政敏感内容感。
  * 应用类似策略到k12审核，预计可以减少35%左右的漏审（预计能够体现在周日的例行统计邮件中）
  * 重跑出版书籍的标签拓展项目，优化模型及融合策略。
    * 针对出版书及网文分别训练embedding模型
    * 优化标签产出模型
    * 优化融合策略（进度约20%）
* 下周计划
  * 产出出版书籍融合人工标签及算法标签的融合策略及结果
  * 机审新需求支持（更新一些新的谐音词、组合词策、昵称审核支持）

---

## Week 2

---

### 03-08

 * 计划
   	* [x] 查找，修复，重跑审核统计任务
    * [x] 书籍标签扩充项目
       * [x] 调整参数，重训fastText模型
       * [x] 找到合适模型，并产出预测数据
       * [ ] 调整过滤及融合方式，产出一版新的结果
 * 完成
    * 查找，修复，重跑审核统计任务。
       * 由于两会期间开启了先审后发，导致暂时无法统计机器审核结果
   * 书籍标签扩充项目
     * 调整参数，重训fastText模型
       * 之前迫于想要尽快产出一版的压力，并没有仔细调整模型。这次为例解决过拟合的问题，调整了epoch 和 dim参数
     * 经过试验，找到了两个较为合适的模型，并产出了两份预测数据
 * 收获
   	* [x] 无

---

### 03-09

* 计划
  * [x] 书籍标签扩充项目
    * [x] 重训第三个模型，产出模型预测结果
    * [x] 调整过滤及融合方式，产出一版新的结果
    * [x] 交付一批重点书籍的结果给运营
* 完成
  * 书籍标签扩充项目
    * 重训第三个模型，产出模型预测结果
    * 调整过滤及融合方式，产出一版新的结果
    * 交付一批重点书籍的结果给运营
* 收获
  * 无

---

### 03-10

* 计划

  * [x] OKR (Objectives and Key Results) 会议
  * [x] 根据模型预测结果调整书籍标签及顺序
  * [x] 融合算法与人工标签

* 完成

  * OKR (Objectives and Key Results) 会议

  * 根据分值为过滤后的模型预测标签排序

  * 将人工标签与算法泛化词也加入最终结果中

    * 出版书籍标签统计数据

    * |                  | 平均标签数 | 书籍覆盖率（至少有1个标签的书籍占比） |
      | ---------------- | ---------- | ------------------------------------- |
      | 人工标签         | 2.9709     | 86.14 %                               |
      | 模型标签         | 4.0721     | 92.91 %                               |
      | 人工+模型        | 5.775      | 98.64 %                               |
      | 人工+模型+泛化词 | 5.8034     | 98.66 %                               |

* 收获

  * 无

---

### 03-11

* 计划
  * [ ] 机器审核敏感词更新
  * [ ] 标签扩充项目交付运营一版新的融合了人工标签的结果
* 完成
* 收获

---

### 03-12

---

### Summary

---

## Week 3

---

### 03-015

---

### 03-16

---

### 03-17

---

### 03-18

---

### 03-19

---

### Summary

---

## Week 4

---

### 03-22

---

### 03-23

---

### 03-24

---

### 03-25

---

### 03-26

---

### Summary

---

## Week 5

---

### 03-29

---

### 03-30

---

### 03-31

---

## Summary of March