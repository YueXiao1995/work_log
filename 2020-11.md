# Work Log of November

---

## Week 1

---

### 11-02

* 计划
  * [x] 将例行统计邮件中的“数据中心”，全部改为“算法”
  * [x] 总结机器审核status判定规则交给人工审核部门
  * [ ] 优化，测试新训练出来的模型
  * [x] 修改ugc审核主服务，bert代理，使得k12文本访问bert k12服务，其余文本访问现有bert服务
  * [ ] 部署k12 bert服务到101， 102， 部署，测试，上线新的bert 代理，ugc主服务
  * [x] 发票报销
* 完成
  * 将例行统计邮件中的“数据中心”，全部改为“算法”
  * 总结机器审核status判定规则交给人工审核部门
  * 修改ugc审核主服务，bert代理，使得k12文本访问bert k12服务，其余文本访问现有bert服务
* 收获
  * 收获

---

### 11-03

* 计划

  * [x] 部署k12 bert服务到101， 102， 部署，测试，上线新的bert 代理，ugc主服务

* 完成

  * 部署k12 bert服务到101， 102， 部署，测试，上线新的bert 代理，ugc主服务

* 收获

  * tmux 命令

    ```bash
    tmux new -s xiaoyue    		# 新建会话 
    exit / (Ctrl+d)	   			# 退出
    tmux detach / (Ctrl+b +d)	# 分离会话
    tmux attach -t xiaoyue 		# 重连会话
    tmux ls 			  	   # 查看当前所有tmux伪窗口
    tmux rename-session -t xiaoyue xy # 重命名会话
    
    # tmux command = prefix key(Ctrl+b) + command key
    # 分屏
    Ctrl+b + Shift（切换数字和符号）+ %（左右分屏）/ "(上下分屏)
    # 在分屏间移动光标
    Ctrl+b + ->/<-
    # 新建windows（类似于操作系统的屏幕）
    Ctrl+b + c
    # 切换屏幕
    Ctrl+b + p(后一个)/n(前一个)/0...n(index)
    ```

---

### 11-04

* 计划
  * [x] 完善关于书价的负评样本的产出，并设定为定时任务，每周一查找上周的样本，并作为附件发送给同事
  * [x] 重新产出一版ugc主服务的审核数据
  * [ ] 重新训练一个ugc模型
* 完成
  * 完善关于书价的负评样本的产出，并设定为定时任务，每周一查找上周的样本，并作为附件发送给同事
  * 重新产出2018-10-31日以来的ugc审核数据
  * 下载centos 为学习hadoop做准备

* 收获
  * 无

---

### 11-05

* 计划
  * [x] 整理所有来源的ugc审核样本，构造新的训练数据集
  * [ ] 训练一个新的ugc模型
  * [x] 虚拟机装机
* 完成
  * 创建 CentOS 虚拟机
    * 完成下载和安装，用户创建，软件安装等工作
  * 整理所有来源的ugc审核样本
  * 沟通协调中台使用k12审核的新功能
* 收获
  * 无

---

### 11-06

* 计划

  * [x] 完成周报
  * [x] 参加分享会
  * [ ] 整理代码，完善注释，整理训练数据
  * [ ] git维护

* 完成

  * 完成周报，总结k12免审模型开发工作及阶段性结果
  * 参加推荐分享会
  * 导出27日机审通过需要人审的所有样本，并请求k12 bert服务。根据结果统计 机审 + 中高风险 总的召回率
  * 发现一个过去忽略的问题：从日志中产出样本时，由于一些文本里本身带有`/n`，导致保存时自动保存为多行，在训练前的预处理环节又会把除第一行以外的文本全部抛弃，导致文本不完整。

* 收获

  * find 命令

    ```bash
    find . -name k12 # 在当前目录及子目录中查  
    ```

---

### 11-08

* 计划

  * [x] 解决训练文本不完整的问题
  * [x] 重新产出k12 及 ugc 的训练数据

* 完成

  * 解决训练文本不完整的问题
  * 重新产出ugc样本（2018-10-31至两日前），及k12样本（2020-07-29至两日前）

* 收获

  * ``` python
    original_text = '你/n好/n啊'
    text = repr(text)  # 保存时 /n 不会自动换行
    text = eval(text)  # 变回普通文本
    ```

---

### Summary

* 修改ugc审核主服务，bert代理，使得k12文本访问bert k12服务，其余文本访问现有bert服务
* 部署k12 bert服务到101， 102， 部署，测试，上线新的bert 代理，ugc主服务
* 重新从日志在产出2018-10-31日以来的ugc审核数据
* 完善关于书价的负评样本的产出，并设定为定时任务，每周一查找上周的样本，并作为附件发送给同事
* 总结机器审核status判定规则交给人工审核部门
* 例行统计邮件维护

---

## Week 2

---

### 11-09

* 计划
  * [x] 测试k12bert服务，与原有的模型进行对比，分析是否可以替代原有的模型
* 完成
  * 使用2020-11-07的数据对模型进行测试，测试结果如下
    * 0.05: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 62307, 8732, 0.140145, 0.980573], ['低风险', 174554, 173, 0.999009, 0.764977]]
      0.1: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 50263, 8638, 0.171856, 0.970017], ['低风险', 186598, 267, 0.998569, 0.817399]]
      0.15: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 44652, 8564, 0.191794, 0.961707], ['低风险', 192209, 341, 0.998226, 0.841689]]
      0.2: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 41158, 8501, 0.206546, 0.954632], ['低风险', 195703, 404, 0.997936, 0.85674]]
      0.25: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 38446, 8428, 0.219217, 0.946435], ['低风险', 198415, 477, 0.997596, 0.868317]]
      0.3: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 35635, 8358, 0.234545, 0.938574], ['低风险', 201226, 547, 0.997282, 0.880341]]
      0.35: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 33806, 8313, 0.245903, 0.93352], ['低风险', 203055, 592, 0.997085, 0.888167]]
      0.4: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 32479, 8258, 0.254257, 0.927344], ['低风险', 204382, 647, 0.996834, 0.893747]]
      0.45: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 31395, 8214, 0.261634, 0.922403], ['低风险', 205466, 691, 0.996637, 0.898309]]
      0.5: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 30246, 8157, 0.269689, 0.916002], ['低风险', 206615, 748, 0.99638, 0.9031]]
      0.55: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 28949, 8092, 0.279526, 0.908703], ['低风险', 207912, 813, 0.99609, 0.908504]]
      0.6: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 27437, 8003, 0.291686, 0.898709], ['低风险', 209424, 902, 0.995693, 0.914747]]
      0.65: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 25630, 7881, 0.307491, 0.885008], ['低风险', 211231, 1024, 0.995152, 0.922138]]
      0.7: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 23635, 7712, 0.326296, 0.86603], ['低风险', 213226, 1193, 0.994405, 0.930149]]
      0.75: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 21364, 7512, 0.35162, 0.843571], ['低风险', 215497, 1393, 0.993536, 0.939234]]
      0.8: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 19282, 7298, 0.378488, 0.81954], ['低风险', 217579, 1607, 0.992614, 0.947428]]
      0.85: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 16374, 6858, 0.418835, 0.770129], ['低风险', 220487, 2047, 0.990716, 0.958255]]
      0.9: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 12918, 6232, 0.482428, 0.699832], ['低风险', 223943, 2673, 0.988064, 0.97067]]
      0.91: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 11884, 5972, 0.502524, 0.670634], ['低风险', 224977, 2933, 0.986963, 0.974065]]
      0.92: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 10699, 5657, 0.528741, 0.635261], ['低风险', 226162, 3248, 0.985639, 0.977882]]
      0.93: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 9475, 5271, 0.556306, 0.591915], ['低风险', 227386, 3634, 0.984018, 0.981558]]
      0.94: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 8334, 4887, 0.586393, 0.548793], ['低风险', 228527, 4018, 0.982418, 0.984879]]
      0.95: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 7345, 4523, 0.615793, 0.507917], ['低风险', 229516, 4382, 0.980908, 0.98762]]
      0.96: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 6226, 4064, 0.652747, 0.456373], ['低风险', 230635, 4841, 0.97901, 0.990516]]
      0.97: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 4771, 3391, 0.710752, 0.380797], ['低风险', 232090, 5514, 0.976242, 0.993946]]
      0.98: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 3296, 2549, 0.773362, 0.286244], ['低风险', 233565, 6356, 0.972787, 0.996723]]
      0.99: [['类别', '总量', '违规量', '精确率', '召回率'], ['高风险', 1954, 1626, 0.832139, 0.182594], ['低风险', 234907, 7279, 0.969013, 0.998561]]
  * 协助审核部门查找人审工作量统计邮件的问题
* 收获
  * 无

---

### 11-10

* 计划
  * [x] 修复例行统计邮件样本附件的错误
  * [ ] 发邮件给相关同事，介绍免审系统的阶段性成果
  * [x] 修改审核主服务，使cs分值大于0.8的高风险文本也被判断为违规
* 完成
  * 修复例行统计邮件样本附件的格式错误
    * 原因：错误地使用了repr()
  * 修改审核主服务，使cs分值大于0.8的高风险文本也被判断为违规， 测试并上线
  * 与数据上游沟通反馈数据的异常
  * 参与推荐系统的分享会
  * 工作邮箱沾满，清理无用邮件
* 收获
  * 无

---

### 11-11

* 计划
  * [x] 清理无用邮件
  * [x] 发邮件给相关同事，介绍免审系统的阶段性成果
  * [ ] 向审核部门简要概述机审的主要逻辑
  * [x] 参加分享会
  * [ ] linux学习
  * [ ] 整理ugc样本
  * [ ] 查看系统中的几个旧模型 TextCNN，XGB
  * [x] 跟hr沟通提取公积金交房租
* 完成
  * 清理无用邮件1400封，约350MB，以后要养成每天早晨查看邮件，清理前一日邮件的习惯
  * 公积金提取相关事项
    * 需要先到银行办理 公积金联名卡，收到卡后需要到银行激活，之后再 FESCO app上进行申请，目前可以每季度提取4500元，全年18000元。
  * 医保存折：每月会上四百多，持存折及工资卡到银行进行关联，钱就会自动打入银行卡
  * 发邮件给看相关同事，介绍免审系统的阶段性成果
  * 参加分享会
* 收获
  * 无
* 想法：
  * 【工作效率提升计划】：
    * 晨读，运动
    * 上班路上阅读，背单词
    * 早晨上班后：
      * 10 分钟查看邮件，清理前一日邮件
      * 10 分钟完善当日工作计划，学习计划
      * 10 分钟温习前日收获
    * 中午：（运动 / 算法题 / 读书 / 睡觉） 四选一
    * 晚上下班前：
      * 15 分钟总计一日的工作成果
      * 总结一日的收获，和新的疑问，想要学习的内容
    * 若正常下班，则用一个小时来学习工作相关技术。
    * 一个小时读书
    * 一个小时学习其他技术
    * 25分钟运动

---

### 11-12

* 计划
  * [x] 向审核部门简要概述机审的主要逻辑
  * [ ] 整理ugc样本
  * [ ] 查看系统中的几个旧模型 TextCNN，XGB
  * [ ] 解决ugc审核中表情符号所导致的漏召回
  * [ ] 查看日志，查找近几日机审失败的原因
* 完成
  * 向审核部门简要概述机审的主要逻辑
  * 没有找到近几日机审失败增多的原因，不过证实确实有异常
  * 表情包导致的漏召回：不确定传入的文本是否如同日志一样经过了转义，明天用一个端口做下试验。确定表情标识后，用正则来识别表情并计数，表情过多的判别为灌水或疑似。
* 收获
  * 无

---

### 11-13

* 计划
  * [x] 完成周报
  * [ ] 解决ugc审核中表情包符号所导致的漏召回
  * [ ] 重新完善k12单个字符的字典
  * [ ] 学习正则表达，学习loging模块用法
  * [ ] 查看系统中的几个旧模型 TextCNN，XGB
* 完成
  * 完成周报
  * 查找k12召回率没有提升的原因，并解决
    * 原因：参数名拼写错误
  * 尝试解决ugc审核中表情包符号所导致的漏召回
* 收获
  * 无

---

### 11-15

* 计划
  * [x] 解决审核邮件发送失败的问题
* 完成
  * 解决审核邮件发送失败的问题
* 收获
  * 无

---

### Summary

* 解决换行符导致的训练文本不完整的问题,  并重新产出ugc样本（2018-10-31以来全部），及k12样本（2020-07-29以来全部）

* 使用2020-11-07日的审核数据测试k12bert服务，与原有的模型进行对比。详细结果说明如下：

  * 在对违规信息的识别方面，新开发的k12 bert模型效果好于原有模型。

    以2020-11-07一日的数据为例， 原有的k12机审模型在识别总量为16198 条的情况下，召回率约为60%，精确率约为 33%。而新的k12 bert模型在大致相同的识别量下（16374条），召回率约为77%，精确率约为42%，均好于原模型。

    以中高风险文本来计算，模型对违规信息的召回率为93.35%，精确率为9.91%。如果中高风险文本结合已有的机审结果（算法原有模型+网易），总的召回率约为97.59 %。

    由于新的k12 bert 模型效果较好，经过讨论决定将cs >= 0.8 的高风险文本直接判定位违规。预计会进一步提高目前k12机审的召回率和精确率。

  *  免审功能方面，依旧以2020-11-07一日为例，当日通过机审后又经过人审的文本量有217822条，其中被新模型判定为低风险文本（免审）的有177797条，占比约为 81.62%， 如果对此部分免审，漏召回的违规样本数为211条，约占违规信息总量的2.37%，约占帖子总量的0.08%。

* 修改审核主服务，使cs分值大于0.8的高风险文本也被判断为违规。预计下周一看到结果。

* 协助审核部门查找人审工作量统计邮件的问题。

* 整理机审的主要逻辑给审核部门

* 尝试解决ugc审核中表情符号所导致的漏召回 （进度约60%）

---

## Week 3

---

### 11-16

* 计划
  * [x] 梳理新项目的大致内容
  * [ ] 查看书籍相似度项目代码
* 完成
  * 梳理新项目的大致内容
  * 与审核及中台沟通，解决k12违规风险识别结果在人审系统内不显示的问题
    * 最终查明的原因为k12会直接同步请求反作弊接口，而非通过中台的自动审核来请求，而他们不会保留请求到的风险识别数据，且正常的文本会直接走人审，不再请求反作弊接口，因此人审系统内所有文本都显示为默认的低风险。
    * 解决办法：k12 开启自动审核，正常文本到达审核中台后，不直接到人审，而是再请求一次反作弊接口，得到风险识别数据后再发给人审。但这样会导致k12的请求量翻倍。需要先确保反作弊服务的性能可以支持。
  * 统计k12 bert 模型识别高风险算作违规信息前后，k12审核的相关数据。
* 收获

---

### 11-17

* 计划
  * [x] 协助中台查找每天固定时段大量报错的原因
  * [ ] 书籍名称简介embedding产出
* 完成
  * 协助中台查找每天固定时段大量报错的原因。
    * 结论：由于中台提供的几个例子在机审服务的日志中找不到，转而在nginx日志中查找。但nginx日志中post请求无法通过msgid匹配，只好用时间段来查找。查找发现所有返回500error的记录，request_time 均超过了500ms, 说明问题的原因与超时有关。由于服务日志中找不到这些请求的记录，因此决定暂时修改k12审核日志的记录方式。由返回前记录日志，改为接收到请求，经过textCNN模型后，经过bert模型后都分别记录一条日志。
  * 修改审核服务，增加日志记录，测试上线
* 收获
  * nginx配置相关

---

### 11-18

* 计划
  * [x] 找到k12审核固定时段 报错 的原因，并修复
  * [x] 整理书籍信息
  * [ ] 训练模型，产出书籍embedding
* 完成
  * 找到k12审核固定时段 报错 的原因，并修复，测试后上线
  * 对书籍信息进行预处理
* 收获
  * 无

---

### 11-19        

* 计划
  * [x] 配置，启动bert server
  * [x] 产出书籍embedding
* 完成
  * 将bert server 部署在了7010、7011端口
  * 产出一部分书籍embedding，以npy的格式保存
    * 发现产出的文件很大，100条书籍简介的embedding，大小在24MB左右，考虑减少特征数
* 收获
  * 无

---

### 11-20

* 计划
  * [x] 重新设置embedding的特征数，产出embedding
  * [ ] 查看已有项目代码。计算书籍相似度
  * [ ] 产出书籍相似度矩阵
* 完成
  * 调整bert server 启动配置，产出书名及书籍简介的embedding
* 收获
  * 无

---

## Summary

* 与审核及中台沟通，查找k12违规风险识别结果在人审系统内不显示的问题
  * 最终查明的原因为k12会直接同步请求反作弊接口，而非通过中台的自动审核来请求，而他们不会保留请求到的风险识别数据，且正常的文本会直接走人审，不再请求反作弊接口，因此人审系统内所有文本都显示为默认的低风险。
  * 解决办法：k12 开启自动审核，正常文本到达审核中台后，不直接到人审，而是再请求一次反作弊接口，得到风险识别数据后再发给人审。但这样会导致k12的请求量翻倍。需要先确保反作弊服务的性能可以支持。
* 协助中台查找每天固定时段大量报错的原因并修复，确保k12开启自动审核后不会有性能问题
  * 原因：在202机器上部署的服务性能有瓶颈，在夜间19-22点请求量增大的情况下会频繁的发生超时问题，导致审核主服务报错。在修改超时设置后，暂时解决了该问题。（由于后面的k12 bert模型的效果好于TextCNN，预计这一改变不会显著影响机审服效果）
* 跟踪统计k12审核新的逻辑（ k12 bert模型识别的高风险也算作违规）上线前后，k12审核的相关数据。
  * 结论：k12 违规机审召回率从55%显著提高至90%左右，准确率维持在40%左右
* 书籍相似度矩阵项目 （进度约50%）
  * 结合精品书籍与平装书的对应关系，对书籍信息进行预处理
  * 在102机器部署bert serving server（占用7010， 7011端口）
  * 批量产出书名及简介的embedding，以npy格式保存

---

## Week 4

---

### 11-23

* 计划
  * [x] 查看已有项目代码。计算书籍相似度
  * [x] 产出书籍相似度矩阵
* 完成
  * 完成书籍相似度计算的相关开发工作
  * 产出5本书的相似度矩阵，用于测试效果
    * 在大批量产出时遇到问题
* 收获
  * 无

---

### 11-24

* 计划

  * [x] 产出完整的书籍相似度矩阵
  * [x] 将用于测试的程序改为交互式，提高效率

* 完成

  * 产出完整的书籍相似度矩阵
  * 将用于测试的程序改为交互式，启动程序后按照提示输入要查询的书籍id，打印结果。

* 收获

  * 查看正在执行的文件的PID

  ```bash
  pgrep -f filename
  ```

  * Python输出缓冲区问题
    * 问题：使用nohup启动脚本，print并未输出到log。
    * 原因：python输出缓冲区要满 4k 才写入文件，除非禁用缓存或者强制输出或者程序结束。python程序stdout会先输出到缓冲区，等缓冲区满或者脚本结束再输出，而print 会调用 sys.stdout 的 write 方法。
    * 解决办法：
      * 运行时加`-u`参数，如 `nohup python3 -u test.py`
  * Linux 监控
    * [Linux 系统查看CPU，内存，磁盘使用率](https://blog.csdn.net/wujizhishui/article/details/89333957)

  ```bash
  top # 查看系统运行状态和CPU、内存利用率
  # PID 进程id
  # USER 进程所有者
  # PR 进程优先级
  # NI nice值
  # VIRT 进程使用虚拟内存总量
  # RES 进程使用物理内存大小
  # SHR 共享内存大小
  # S 进程状态（D不可中断的睡眠吗，R运行，S睡眠，T跟踪/停止，Z僵尸）
  # %CPU 上次更新到现在的CPU时间占用百分比 （%CPU显示的是进程占用一个核的百分比，而不是整个cpu的百分比，有时候可能大于100，那是因为该进程启用了多线程占用了多个核心，所以有时候我们看该值得时候会超过100%，但不会超过总核数*100）
  # %MEM 进程使用的物理内存百分比
  # TIME+ 进程使用的CPU时间总计，单位1/100秒
  # COMMAND 进程名称（命令名/命令行）
  #（参考: https://www.cnblogs.com/zhoug2020/p/6336453.html）
  
  vmstat 1 10 # 两个参数分别为 采集时间间隔（单位为秒）和 采样次数
  # r：在运行队列中等待的进程数
  # b：在等待io的进程数
  # swpd：现时可用的交换内存（单位KB）
  # free：空闲的内存（单位KB）
  # buff: 缓冲去中的内存数（单位：KB）
  # cache：被用来做为高速缓存的内存数（单位：KB）
  # 。。。
  #(参考：https://blog.csdn.net/wujizhishui/article/details/89333991)
  
  free -m # 显示Linux系统中空闲的、已用的物理内存及swap内存，及被内核使用的buffer。可选参数 b, k, m, g
  # total: 总计物理内存的大小。
  # used: 已使用多大。
  # free: 可用有多少。
  # Shared: 多个进程共享的内存总额。
  # Buff/cache: 磁盘缓存的大小。
  
  df -h # 查看磁盘使用率
  # Filesystem：代表该文件系统时哪个分区，所以列出的是设备名称。
  # 1K-blocks：说明下面的数字单位是1KB，可利用-h或-m来改变单位大小，也可以用-B来设置。
  # Used：已经使用的空间大小。
  # Available：剩余的空间大小。
  # Use%：磁盘使用率。如果使用率在90%以上时，就需要注意了，避免磁盘容量不足出现系统问题，尤其是对于文件内容增加较快的情况(如/home、/var/spool/mail等)。
  # Mounted on：磁盘挂载的目录，即该磁盘挂载到了哪个目录下面。
  
  gpuinfo # 监控GPU使用情况
  ```

---

### 11-25

* 计划
  * [x] 解决相似书籍查询的bug
  * [x] 解决k12审核昨晚打开自动审核后超时的问题
* 完成
  * 解决相似书籍查询的bug
    * 问题1：有部书籍id在“书名” 和 “简介”两个相似度矩阵中找不到，没有相关的记录
    * 原因：之前没有考虑到同名书，或相同简介的问题。如果存在相同书名或简介，faiss算出的diff就有多个0的可能性，而且按照diff排序，目标id很可能不在首位。
    * 问题2：有的书籍id搜索不到相似书籍
    * 原因：平装书和精装书的copyrightcode可能不一样，比如有的平装书的版权过期了，但是精装书的却没有。在数据预处理时我以为是一致的，所以就按照平装书的版权来判断，导致丢掉了很多数据。
    * 解决：重写数据预处理代码，重新跑一版embedding 和 similarity matrix
  * 查找k12 自动审核打开后超时的问题
    * 原因：k12审核的自动审核打开后，请求量翻倍，导致高峰时段TextCNN模型服务无法支持。
* 收获
  * 无

---

### 11-26

* 计划
  * [x] 重新产出书籍相似度矩阵
  * [x] 对k12 TextCNN服务进行压测，尝试提升服务性能，或迁移逻辑。
* 完成
  * 重新产出书籍相似度矩阵，预计耗时27小时，预计明天中午两点产出。
  * 对k12 TextCNN模型服务进行压测。
  * 尝试提升服务性能。尝试失败。查看代码发现k12并无逻辑。
  * 修改审核主服务代码，下掉k12的textCNN模型，使得k12只过一个bert模型，以支持k12开启自动审核所增加的一倍请求量。
    * 下掉CNN模型对机审效果的影响有待跟进
  * 与审核部门进行沟通，确认风险提示功能上线成功
* 收获
  * 无

---

### 11-29

* 计划
  * [ ] 产出书籍相似度矩阵
  * [ ] 修改测试脚本
* 完成
  * 产出书籍相似度矩阵
  * 修改测试脚本
* 收获
  * 无

---

## Summary

* 本周完成：

  * 根据书籍名称及书籍简介的embedding，产出相似度矩阵
  * 完成交互式的测试脚本，输入一个bid，输出相似度高的书籍的信息
  * 由于平装、精装书的copyright存在不一致的情况，导致预处理阶段丢弃了过多的数据，因此重新产出了一版embedding及similarity matrix
  * 查找k12自动审核功能打开后超时严重的原因，并尝试解决。
    * 问题原因：k12审核在请求TextCNN服务时大量超时，性能存在瓶颈。
    * 解决办法：暂时停用了k12的TextCNN模型，k12审核只过Bert模型，并修改违规阈值。对违规识别的效果的影响有待跟进。
  * 沟通协调中台及审核部门，完成k12风险识别功能的上线。

  

* 下周计划：

  * 跟进停用k12 TextCNN模型对k12审核的影响。
  * 尝试提升TextCNN模型服务的性能。

---

### 11-30

* 计划
  * [x] 熟悉书籍tag产出项目
  * [ ] 写wiki总结之前的书籍相似度项目 及 k12 审核项目
  * [x] 发票相关事务
* 完成
  * 熟悉书籍tag项目 （进度10%）
  * 收集，打印发票
* 收获
  * 无

---

## Summary of November

* 完成