# Work Log of January

---

## Week 1

---

### 01-04

* 计划
  * [ ] 外部网站书籍标签爬取，查看学习相关项目
  * [ ] 将每周一例行产出的阅文书高风险书评中已经被删除的书评剔除
  * [ ] “审核统计&样本产出” 项目下开发脚本，发送指定日期的统计邮件
  * [ ] 发票报销
* 完成
  * 学习了解 Scarpy，包括关键整体结构，关键组件，具体任务流程
  * 速看项目产出数据有问题，原因查找并修改代码，重新产出书籍标签映射结果
* 收获
  * 无

---

### 01-05

* 计划
  * [x] 使用最新数据重跑书籍标签映射
  * [x] 整理数据及代码，设为每日例行任务
  * [ ] 学习使用Scarpy爬取书籍标签
* 完成
  * 使用最新数据重跑书籍标签映射
    * 修改了映射关系文件
    * 对相关标签按照相关次数进行排序
    * 剔除平装书，仅保留精装书
  * 完成运行整个项目的脚本，包括原始数据下载，标签映射，数据上传等，并设为每日例行任务
  * 根据运营给予的标签互斥关系，去掉关联标签中的一些不合理的标签
* 收获
  * 无

---

### 01-06

* 计划
  * [x] 解决速看标签项目中既是男频又是女频的书籍的标签问题
  * [ ] 学习使用Scarpy爬取书籍标签
* 完成
  * 解决了速看标签项目中一些既是男频也是女频的书的标签问题
    * 使这些书同时有男女频两类标签
  * 开会分享tag项目基本概况
  * 整理注释代码
  * 修改速看标签项目例行脚本，上传结果前检查产出结果，上传后请求调度系统
* 收获
  * 无

---

### 01-07

* 计划
  * [x] 从书籍tag项目中导出缺少前三章数据的书籍id
  * [ ] 修改脚本，统计不同特征域对于书籍最终标签的影响
  * [ ] 整理项目代码
  * [ ] k12审核增加敏感词
  * [ ] 查找1月5日机审失败数据激增的原因
  * [x] 设置例行任务，同步速看标签数据
* 完成
  * 报销发票登记整理
  * 为审核部门讲解统计邮件
  * 修改速看标签例行任务脚本，将数据同步到11机器的对外服务目录下
  * 从书籍tag项目中导出缺少前三章数据的书籍id
  * 学习创建scrapy项目，运行demo
* 收获
  * 无

---

### 01-08

* 计划
  * 参加代码review
  * 学习使用Scrapy
  * 整理外部网站标签与我们的标签的交，并，差集
* 完成
  * 整理外部网站标签与我们的标签的交，并，差集
  * 学习使用Scrapy，爬取目标网站的教师姓名，职称等信息
* 收获
  * 无

---

### Summary

* 本周完成
  * 速看项目
    * 根据测试、运营反馈，调整标签映射逻辑。
    * 根据运营给予的速看标签互斥关系，去掉映射结果中一些不合理的标签。
    * 对于一些既是男频也是女频的书籍，映射男女频两类标签。
    * 完成速看标签项目例行产出的脚本，设置为每日任务，并将结果同步到对外数据服务接口。
  * tag项目
    * 导出缺失头三章数据的书籍
    * 整理统计外部网站标签与掌阅标签的交、并、差集
  * 其他：
    * 代码注释
    * 发票报销登记
    * 开会讲解书籍tag产出项目
* 下周计划
  * 从外部网站获取书籍标签等信息。
  * 与掌阅已有的标签进行对比分析，丰富标签量。
  * 统计书籍tag产出的最终结果中，不同特征域的影响，具体到每个域贡献了哪些标签。
  * 书籍的新标签匹配模块开发，新增书籍标签统计分析。 

---

## Week 2

---

### 01-11

* 计划
  * [ ] 统计书籍tag产出的最终结果中，不同特征域的影响，具体到每个域贡献了哪些标签。
  * [ ] 从外部网站获取书籍标签等信息。与掌阅已有的标签进行对比分析，丰富标签量。
  * [ ] 书籍的新标签匹配模块开发，新增书籍标签统计分析
* 完成
  * 根据审核部门反馈问题，查找添加敏感词不生效的原因，并重启机审服务。
  * 查找k12审核部分结果异常的原因
    * 经排查，原因如下：12月29号，我们将书城审核 bert免审模型 cs>0.9的算做了违规（status=1）。 由于我们用来区分使用书城模型还是k12模型的参数是t=k12，所以caller=k12的请求也一直在走书城的免审模型，所以12月29号后，两个句号这样的cs>0.9的k12请求就也被直接算作违规了。
  * 产出一版书籍信息（含有top100关键词）（进度50%）
  * 开会讨论书籍tag扩充项目
  * 迁移重启bert服务
* 收获
  * 无

---

### 01-12

* 计划
  * [x] 总结k12审核使用caller和t参数分别会经过哪些校验，维护wiki文档
  * [x] 修改机审项目逻辑，暂时将caller=k12的请求结果恢复到12月29号之前的版本
  * [ ] 产出一版书籍信息（含有top100关键词）
  * [ ] 对比外部网站书籍标签与我们自己的书籍标签
* 完成
  * 总结k12审核使用caller和t参数分别会经过哪些校验，维护wiki文档
  * 修改机审项目逻辑，暂时将caller=k12的请求结果恢复到12月29号之前的版本，问题解决
  * 对比外部网站书籍标签与我们自己的书籍标签 [20%]
* 收获
  * 前一天重启bert服务时，可能由于GPU被占用，导致服务没有使用GPU，而是使用了CPU，导致从昨天到今天早上相应时间一直在200~500ms之间，产生大量超时报错，早晨排查到问题后，重启项目，恢复服务正常运转。
    * 重启服务后，要观察一段时间的日志，并且改了什么就要观察什么。端口占用，内存占用，gpu、cpu占用，相应时间等。

---

### 01-13

* 计划
  * [ ] 匹配外部网站书籍标签信息，统计标签覆盖情况
* 完成
  * 匹配外部网站书籍标签信息，统计标签覆盖情况 (50%)
    * 完成（1）数据处理、加载， 重名书籍过滤，（2）书籍通过书名进行匹配，并保存结果 两部分的代码
  * 统计外部网站标签的频次，排序后导出交付运营
* 收获

---

### 01-14

* 计划
  * [x] 匹配外部网站书籍标签信息，统计标签覆盖情况
  * [x] 在书籍标签例行产出项目中，加入一个人工设定的干预字典，去除运营认为不合理的标签
* 完成
  * 匹配外部网站书籍标签信息，统计标签覆盖情况 (80%)
    * 掌阅：
      * 男、女频网文：134346
      * 带算法标签书籍：131825
      * 无重名书籍：60642
    * tsj：
      * 无重名书籍：58858
    * 根据书名匹配无重名书籍：4881
  * 在书籍标签例行产出项目中，加入一个人工设定的干预字典，去除运营认为不合理的标签
    * 需要检查周五的例行产出结果是否正常
* 收获
  * 无
* 收获

---

### 01-15

* 计划
  * [ ] 将从外部网站获取的tags加入现有标签库，修改书籍标签产出项目，产出一版书籍tag与现有结果进行比较，并统计标签对书籍的覆盖情况及书籍的标签量等数据
  * [x] 设置定时任务，定期重启机器审核服务
  * [x] 周会，周报
  * [x] 完成转正申请
* 完成
  * 书籍标签tag项目，由于前一天的改动，书籍tag产出失败，查看日志定位原因，修复后重跑产出结果
  * 周会，周报
  * 设置定时任务，每周一早晨4点重启机审服务
  * 转正申请：
    * 内容：试用期工作总结需包括试用期工作业绩描述、对公司及本部门的认识和建议、工作中遇到的困难和存在的不足、转正后工作计划以及对个人职业规划等内容。
      * 试用工期业绩描述：
        * 接手机器审核项目，找到了接手前统计数据中ugc审核灌水召回率骤降的原因，9月16日 审核中台将灌水贴的识别依据，由使用网易结果全部切换为使用算法识别的结果后，数据恢复正常。维护、升级机审结果的例行统计项目，可视化审核统计结果，从审核日志中例行产出各类样本。
        * 开发免审模型（风险识别模型）：
          * 完成免审模型的开发，并将之服务化，于10月14日上线。并将相关统计结果加入例行邮件。统计结果显示， 在允许极少量遗漏（占比违规总量3%以内）的情况下，UGC审核可以从全审做到书城的60%免审，K12可以从12%免审做到80%免审。
          * 于12月16审核中台完成了相应的排序和筛选功能支持，业务方开始正式使用。
        * K12机器审核的优化：11月15日前后审核结果统计数据显示在违规识别精确率从38%提升到50%左右的情况下，召回率由55%提高到89%。下线网易审核模型对k12违规召回率的影响为1%左右。
        * 支持新速看项目开发，通过开发优化映射逻辑，将新的标签体系应用于该项目所涉及的书籍上，项目与1月6日完成上线。
      * 工作中遇到的困难和存在的不足
        * 困难
          * 初期有些难以适应工作强度，做不到精神长期高度集中。
          * 经验不足，理解掌握老项目有难度，往往在看代码的同时，还需要学习其中的一些技术才能够顺利理清项目。
          * 一些老项目，由于时间久远且经手人很多，导致代码风格不统一，缺少注释，变量、函数名含义不明，造成一些逻辑难以理解，改动时难度较大。
        * 不足：
          * 由于不熟悉纯命令行的生产环境，客观上限制了工作效率。
          * 跟业务方沟通时，有时不能快速准确理地解对方的意涵和需求。
          * 代码跑通，项目上线就万事大吉，缺乏系统的归纳和总结，缺乏深入思考。
          * 有时对于目标理解不够明确，导致花了很大的精力做的事情，实际意义不大。
      * 转正后工作计划以及对个人职业规划
        * 工作计划：做好自己负责、参与的项目。对完成的工作有计划地进行归纳和总结。找到不足的地方，有针对性的进行提高。最终上线提工作效率，代码质量，项目完成质量的提高。
        * 职业规划：
          * 短期：计划用两年的时间，打牢技术方面的基本功，熟练掌握工作中常用的技术和工具，对算法相关的各个领域的工作都能快速上手，能做出一定的成绩。
          * 中期：之后再用两到三年的时间，去深入探索一些在业界较为前沿的技术，理解它们的设计思路，应用之外能够有更深层次的思考。针对具体的需求，也能够结合不同技术方案优缺点，找出最合适的实现方案。
          * 长期：把握技术发展方向，有系统的知识储备。
* 收获
  * 无

---

### summary

* 本周完成
  * 书籍tag扩充项目
    * 处理从外部网站获取的书籍标签数据，根据书名匹配掌阅书籍，产出部分书籍（4881本）加入外部网站数据后的书籍标签。
      * 数据处理、加载， 重名书籍过滤
      * 书籍通过书名进行匹配，输出匹配结果
    * 在书籍tag项目中加入人工干预逻辑，根据运营反馈修改最终产出的书籍tag。
    * 统计外部网站标签的频次，排序后导出交付运营
  * 机器审核
    * 查找添加敏感词不生效的原因，并重启机审服务。
    * 根据审核部门反馈，定位k12审核部分结果不合理的原因，并进行修复。
      * 原因: 12月29号，我们将书城审核 bert免审模型 cs>0.9的算做了违规（status=1）。 由于我们用来区分使用书城模型还是k12模型的参数是t=k12，所以caller=k12的请求也一直在走书城的免审模型，所以12月29号后，两个句号这样的cs>0.9的k12请求就也被直接算作违规了。
      * 修复: 修改机审项目逻辑，暂时将caller=k12的请求结果恢复到12月29号之前的版本，问题解决。
    * 总结k12审核使用caller和t参数分别会经过哪些校验，维护wiki文档
* 下周计划
  * 将从外部网站获取的tags加入现有标签库，修改书籍标签产出项目，产出一版书籍tag与现有结果进行比较，并统计标签对书籍的覆盖情况及书籍的标签量等数据。
  * 统计匹配结果中的书籍占热门书籍的比例。

---

## Week 3

---

### 01-18

* 计划
  * [x] 将从外部网站获取的tags加入现有标签库，修改书籍标签产出项目，产出一版书籍tag与现有结果进行比较，并统计标签对书籍的覆盖情况及书籍的标签量等数据。
  * [ ] 统计匹配结果中的书籍占热门书籍的比例。
  * [ ] 在统计邮件的 ‘网易召回’ 附件中加入一列 ‘风险识别结果’
* 完成
  * 查找例行统计邮件发送失败原因，修复后重发邮件
  * 将从外部网站获取的tags加入现有标签库，修改书籍标签产出项目，产出一版书籍tag与现有结果进行比较
    * 先跑了一百本进行测试
    * 后跑了与外部网站匹配到的4881本
* 收获
  * 无

---

### 01-19

* 计划
  * [x] 计算热门书籍（按照点击量排）中，与外部网站匹配到的书籍所占的比例。
  * [x] 在统计邮件的 ‘网易召回’ 附件中加入一列 ‘风险识别结果’
* 完成
  * 计算热门书籍（按照点击量排）中，与外部网站匹配到的书籍所占的比例。
  * 统计匹配到的书籍中，外部标签，与我们内部标签的比例
  * 在统计邮件的 ‘网易召回’ 附件中加入一列 ‘风险识别结果’
* 收获
  * 无

---

### 01-20

* 计划
  * [x] 使用 书名+作者 的方式匹配书籍
    * [x] 产出新增的外部标签，交付运营审核
    * [ ] 将审核后的标签加入标签库
    * [x] 修改代码，使用书名+作者的方式匹配书籍
  * [ ] 产出一份关于重点出版书籍的信息，包含豆瓣标签，关键词等
* 完成
  * 开会讨论书籍标签扩充项目
  * 产出新增的外部标签，交付运营审核
  * 修改代码，使用书名+作者的方式匹配书籍
  * 产出一份关于重点出版书籍的信息，包含豆瓣标签，关键词等（20%）
* 收获
  * 无

---

### 01-21

* 计划
  * [x] 产出一份关于重点出版书籍的信息，包含豆瓣标签，关键词等
  * [x] 将新增的外部标签加入，重新产出一份按照 书名+作者  匹配后的结果
* 完成
  * 产出一份关于重点出版书籍的信息，包含豆瓣标签，关键词等
  * 将新增的外部标签加入，重新产出一份按照 书名+作者  匹配后的结果
  * 过滤，产出网文和出版书籍的新增标签，交付对接人
* 收获
  * 无

---

### 01-22

* 计划
  * [ ] 使用tastText模型，从样本中产出标签
    * [ ] 使用jieba对豆瓣书简介进行分词，结合过滤后的豆瓣标签，构造数据
    * [ ] 使用模型进行训练
  * [ ] 新速看项目，产出数据中加入标签热度
  * [ ] 出版书籍豆瓣标签爬取
* 完成
  * 使用tastText模型，从样本中产出标签（50%）
    * 已完成数据集构造
    * 准备进行模型训练
* 收获
  * 无

---

### summary

* 本周完成
  * 将外部网站网文tag加入标签库，针对通过书名匹配到的4881本网文书，采用现有的方式产出一版书籍tag。
    * 结论：效果不佳，新增标签与外部网站爬取结果差异较大。
  * 计算匹配到的外部网站书籍，占掌阅热门书籍的比例（根据60天收入）。
    * 8.6左右
  * 使用 书名+作者 方式 匹配书籍，产出匹配后的标签结果
    * 4400本
  * 产出一包含重点书籍的豆瓣标签，关键词等信息的数据
  * 在统计邮件的 ‘网易召回’ 附件中加入一列 ‘风险识别结果’
    * {'机审违规': 10, 'bert违规': 4, '高风险': 19, '中风险': 8, '低风险': 9}
    * 低等风险中5条是表情灌水
* 下周计划
  * 使用tastText模型，从样本中产出标签
    * [ ] 使用jieba对豆瓣书简介进行分词，结合过滤后的豆瓣标签，构造数据
    * [ ] 使用模型进行训练
  * [ ] 新速看项目，产出数据中加入标签热度
  * [ ] 出版书籍豆瓣标签爬取

---

## Week 4

---

### 01-25

* 计划

  * [x] 使用tastText模型，从样本中产出标签
    * [x] 使用构造好的数据训练模型，挑选效果最好的模型
    * [x] 使用模型通过书籍简介，预测书籍标签

* 完成

  * 使用tastText模型，从样本中产出标签

    * 使用构造好的数据训练模型，挑选效果最好的模型

    * 使用模型通过书籍简介，预测书籍标签

* 收获

  * 无

---

### 01-26

* 计划
  * [x] 统计每个标签在不同阈值下的召回、精确和f值，取 f 值最大时的 阈值，用来过滤模型预测结果，产出一版过滤后的结果
* 完成
  * 统计每个标签在不同阈值下的召回、精确和f值，取 f 值最大时的 阈值，用来过滤模型预测结果，产出一版过滤后的结果
* 收获
  * 无

---

### 01-27

* 计划
  * [x] 开发脚本，使得既可以使用f，也可以使用p来选取每个标签的阈值
  * [x] 使用不同的p值，计算标签相对应的阈值，并产出几版过滤后的预测结果
  * [x] 开发脚本，产出一份可以对比不同方案最终结果的数据，并统计每个方案的相关指标
* 完成
  * 开发脚本，使得既可以使用f，也可以使用p来选取每个标签的阈值
  * 使用不同的p值，计算标签相对应的阈值，并产出几版过滤后的预测结果
  * 根据需求，为平台产出一分fid数据
  * 开发脚本，产出一份可以对比不同方案最终结果的数据，并统计每个方案的相关指标
* 收获
  * 无

---

### 01-28

* 计划
  * [x] 使用书名+简介+人工关节词，产出一版标签交付运营评审
  * [ ] 使用掌阅的出版书籍分类作为标签，预训练一个fasttext模型。之后再使用豆瓣标签数据对模型进行训练。
  * [ ] 针对网文书籍，也使用fasttext训练模型，产出一版预测结果
* 完成
  * 使用书名+简介+人工关节词，产出一版标签交付运营评审
  * 发票报销
  * 机审k12增加关键词“点赞，求赞，拿图，取图”
* 收获
  * 无

---

### 01-29

* 计划
  * [ ] 使用掌阅的出版书籍分类作为标签，预训练t模型。之后再使用豆瓣标签数据对模型进行训练。
  * [ ] 针对网文书籍，训练fasttext模型，产出一版预测结果
  * [ ] 新速看项目，产出数据中加入标签热度
* 完成
  * 根据运营需要，导出速看项目网文标签映射结果
  * 测试反馈得间女频热门标签很少，查找问题原因，采取临时方案暂时解决
* 收获

---

### summary

* 本周完成
  * 对从豆瓣爬取的标签数据进行过滤，构造数据集。
  * 训练，测试多版fastText模型，从中挑选出效果较好的模型。
  * 针对数据集，使用模型产出新标签，统计每个标签在不同阈值下的召回率、精确率和f值
  * 取 f 值最大时的标签阈值，用来过滤模型预测结果，产出一版过滤后的结果
  * 使用不同的精确率值相对应的阈值，并产出几版过滤后的预测结果
  * 使用书名+简介+人工关节词作为原始数据进行训练，使用精确率大等0.7时对应的标签阈值进行过滤，产出一版标签交付运营评审
* 下周计划
  * [ ] 使用掌阅的出版书籍分类作为标签，预训练t模型。之后再使用豆瓣标签数据对模型进行训练。
  * [ ] 针对网文书籍，训练fasttext模型，产出一版预测结果
  * [ ] 新速看项目，产出数据中加入标签热度
  * [ ] 出版书籍豆瓣标签爬取
  * [ ] 在标签产出过程中使用书籍前十章数据

---

## Summary of January





